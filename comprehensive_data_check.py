import pandas as pd
import os
import glob

def check_all_data_sources():
    print("=== ğŸ” å…¨é¢æ•°æ®çŠ¶æ€æ£€æµ‹ ===")
    
    # 1. æ£€æµ‹åŸå§‹åŸºå› ç»„æ–‡ä»¶
    print("\n1. ğŸ“ åŸå§‹åŸºå› ç»„æ–‡ä»¶:")
    gca_fna = glob.glob("clean_genome/GCA_*.fna")
    gcf_fna = glob.glob("clean_genome/GCF_*.fna") 
    all_fna = glob.glob("clean_genome/*.fna")
    
    print(f"   GCAæ–‡ä»¶: {len(gca_fna)}")
    print(f"   GCFæ–‡ä»¶: {len(gcf_fna)}")
    print(f"   æ€»æ–‡ä»¶: {len(all_fna)}")
    
    # 2. æ£€æµ‹Baktaæ³¨é‡Šç»“æœ
    print("\n2. ğŸ”¬ Baktaæ³¨é‡Šç»“æœ:")
    bakta_gca = glob.glob("bakta_annotations/GCA_*")
    bakta_gcf = glob.glob("bakta_annotations/GCF_*")
    bakta_all = glob.glob("bakta_annotations/*/")
    
    print(f"   GCAæ³¨é‡Š: {len(bakta_gca)}")
    print(f"   GCFæ³¨é‡Š: {len(bakta_gcf)}")
    print(f"   æ€»æ³¨é‡Š: {len(bakta_all)}")
    
    # 3. æ£€æµ‹Prokkaæ³¨é‡Šç»“æœ
    print("\n3. ğŸ§¬ Prokkaæ³¨é‡Šç»“æœ:")
    prokka_gca = glob.glob("prokka_annotations/GCA_*")
    prokka_gcf = glob.glob("prokka_annotations/GCF_*") 
    prokka_all = glob.glob("prokka_annotations/*/")
    
    print(f"   GCAæ³¨é‡Š: {len(prokka_gca)}")
    print(f"   GCFæ³¨é‡Š: {len(prokka_gcf)}")
    print(f"   æ€»æ³¨é‡Š: {len(prokka_all)}")
    
    # 4. æ£€æµ‹Roaryè¾“å…¥GFFæ–‡ä»¶
    print("\n4. ğŸ“Š Roaryè¾“å…¥GFFæ–‡ä»¶:")
    roary_gca = glob.glob("roary_input/GCA_*.gff")
    roary_gcf = glob.glob("roary_input/GCF_*.gff")
    roary_all = glob.glob("roary_input/*.gff")
    
    print(f"   GCA GFF: {len(roary_gca)}")
    print(f"   GCF GFF: {len(roary_gcf)}")
    print(f"   æ€»GFF: {len(roary_all)}")
    
    # 5. æ£€æµ‹Roaryè¾“å‡ºä¸­çš„èŒæ ª
    print("\n5. ğŸ¯ Roaryè¾“å‡ºèŒæ ªåˆ†æ:")
    try:
        gene_pa = pd.read_csv('roary_output_final_1762658265/gene_presence_absence.csv', low_memory=False)
        strain_columns = gene_pa.columns[14:]
        
        gca_strains = [s for s in strain_columns if 'GCA_' in s]
        gcf_strains = [s for s in strain_columns if 'GCF_' in s]
        other_strains = [s for s in strain_columns if 'GCA_' not in s and 'GCF_' not in s]
        
        print(f"   GCAèŒæ ª: {len(gca_strains)}")
        print(f"   GCFèŒæ ª: {len(gcf_strains)}")
        print(f"   å…¶ä»–èŒæ ª: {len(other_strains)}")
        print(f"   æ€»èŒæ ª: {len(strain_columns)}")
        
        # æ˜¾ç¤ºå‰5ä¸ªèŒæ ªç¤ºä¾‹
        print(f"   èŒæ ªç¤ºä¾‹: {strain_columns[:3].tolist()}")
        
    except Exception as e:
        print(f"   è¯»å–Roaryæ–‡ä»¶é”™è¯¯: {e}")
    
    return {
        'clean_genome': {'gca': len(gca_fna), 'gcf': len(gcf_fna), 'total': len(all_fna)},
        'bakta': {'gca': len(bakta_gca), 'gcf': len(bakta_gcf), 'total': len(bakta_all)},
        'prokka': {'gca': len(prokka_gca), 'gcf': len(prokka_gcf), 'total': len(prokka_all)},
        'roary_input': {'gca': len(roary_gca), 'gcf': len(roary_gcf), 'total': len(roary_all)},
        'roary_output': {'gca': len(gca_strains), 'gcf': len(gcf_strains), 'total': len(strain_columns)}
    }

def check_data_consistency(results):
    print("\n=== ğŸ”„ æ•°æ®ä¸€è‡´æ€§åˆ†æ ===")
    
    # æ£€æŸ¥å„é˜¶æ®µæ•°æ®é‡æ˜¯å¦åŒ¹é…
    stages = ['clean_genome', 'bakta', 'prokka', 'roary_input', 'roary_output']
    
    print("å„é˜¶æ®µGCAæ•°æ®é‡:")
    for stage in stages:
        if stage in results:
            print(f"   {stage}: {results[stage]['gca']}")
    
    print(f"\nä¸€è‡´æ€§çŠ¶æ€:")
    gca_counts = [results[stage]['gca'] for stage in stages if stage in results]
    
    if len(set(gca_counts)) == 1:
        print("   âœ… æ‰€æœ‰é˜¶æ®µGCAæ•°æ®é‡ä¸€è‡´")
    else:
        print("   âš ï¸  GCAæ•°æ®é‡ä¸ä¸€è‡´")
        for stage in stages:
            if stage in results:
                print(f"      {stage}: {results[stage]['gca']}")

def find_actual_working_set():
    print("\n=== ğŸ¯ ç¡®å®šå®é™…å·¥ä½œæ•°æ®é›† ===")
    
    # æ‰¾å‡ºçœŸæ­£å¯ç”¨çš„GCAæ•°æ®é›†
    sources = {
        'clean_genome': set([os.path.basename(f).replace('.fna', '') for f in glob.glob("clean_genome/GCA_*.fna")]),
        'bakta': set([os.path.basename(d) for d in glob.glob("bakta_annotations/GCA_*")]),
        'prokka': set([os.path.basename(d) for d in glob.glob("prokka_annotations/GCA_*")]),
        'roary_input': set([os.path.basename(f).replace('.gff', '') for f in glob.glob("roary_input/GCA_*.gff")])
    }
    
    print("å„æºGCAæ ‡è¯†æ•°é‡:")
    for source, ids in sources.items():
        print(f"   {source}: {len(ids)}")
    
    # æ‰¾å‡ºæ‰€æœ‰æºä¸­éƒ½å­˜åœ¨çš„GCA
    common_gca = set.intersection(*[ids for ids in sources.values() if ids])
    
    print(f"\nå…±åŒå­˜åœ¨çš„GCAæ•°é‡: {len(common_gca)}")
    if common_gca:
        print(f"ç¤ºä¾‹: {list(common_gca)[:3]}")
    
    return common_gca

if __name__ == "__main__":
    results = check_all_data_sources()
    check_data_consistency(results)
    common_gca = find_actual_working_set()
    
    print(f"\n=== ğŸ’¡ å»ºè®® ===")
    print(f"åŸºäºæ£€æµ‹ç»“æœï¼Œä½ çš„å®é™…å·¥ä½œæ•°æ®é›†åŒ…å« {len(common_gca)} ä¸ªGCAåŸºå› ç»„")
    print("ä¸‹ä¸€æ­¥åº”è¯¥åŸºäºè¿™ä¸ªä¸€è‡´çš„æ•°æ®é›†é‡æ–°åˆ†æ")
