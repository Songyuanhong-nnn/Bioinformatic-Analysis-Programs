import pandas as pd
import argparse
from pathlib import Path
import shutil
from datetime import datetime

def excel_filter_gcf_override(
    input_file: str,
    strain_col: str = "Strain_ID",  # å­˜å‚¨GCA/GCFæ ‡è¯†çš„åˆ—åï¼ˆé»˜è®¤Strain_IDï¼‰
    subset: list = None,
    keep: str = "first",
    ignore_null: bool = True
) -> None:
    """
    Excelç­›é€‰å·¥å…·ï¼šä¿ç•™GCF_å‰ç¼€è¡Œï¼Œåˆ é™¤GCA_å‰ç¼€è¡Œï¼ˆç›´æ¥è¦†ç›–æºæ–‡ä»¶ï¼‰
    :param input_file: è¾“å…¥Excelæ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ.xlsx/.xlsï¼‰
    :param strain_col: å­˜å‚¨GCA/GCFæ ‡è¯†çš„åˆ—åï¼ˆé»˜è®¤ï¼šStrain_IDï¼‰
    :param subset: ç­›é€‰åé¢å¤–å»é‡çš„åŸºå‡†åˆ—ï¼ˆåˆ—è¡¨æ ¼å¼ï¼Œé»˜è®¤ï¼šä¸é¢å¤–å»é‡ï¼‰
    :param keep: é‡å¤è¡Œä¿ç•™ç­–ç•¥ï¼ˆ"first"/"last"/Falseï¼Œé»˜è®¤ï¼šfirstï¼‰
    :param ignore_null: æ˜¯å¦å¿½ç•¥ç©ºå€¼å·®å¼‚ï¼ˆé»˜è®¤ï¼šå¿½ç•¥ï¼‰
    """
    # 1. æ ¡éªŒè¾“å…¥æ–‡ä»¶
    input_path = Path(input_file)
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{input_file}")
    if input_path.suffix not in [".xlsx", ".xls"]:
        raise ValueError("ä»…æ”¯æŒ.xlsxå’Œ.xlsæ ¼å¼çš„Excelæ–‡ä»¶")
    
    # 2. ç”Ÿæˆæºæ–‡ä»¶å¤‡ä»½ï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰
    backup_suffix = datetime.now().strftime("%Y%m%d%H%M%S")
    backup_file = input_path.parent / f"{input_path.stem}_backup_{backup_suffix}{input_path.suffix}"
    try:
        shutil.copy2(input_file, backup_file)
        print(f"ğŸ”§ å·²ç”Ÿæˆæºæ–‡ä»¶å¤‡ä»½ï¼š{backup_file}")
    except Exception as e:
        raise RuntimeError(f"ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å¤±è´¥ï¼š{str(e)}")
    
    # 3. è¯»å–Excelæ–‡ä»¶
    try:
        engine = "openpyxl" if input_path.suffix == ".xlsx" else "xlrd"
        df = pd.read_excel(input_file, engine=engine)
    except Exception as e:
        raise RuntimeError(f"è¯»å–Excelå¤±è´¥ï¼š{str(e)}")
    
    # 4. æ ¡éªŒStrain_IDåˆ—æ˜¯å¦å­˜åœ¨
    if strain_col not in df.columns:
        raise KeyError(f"Excelä¸­æœªæ‰¾åˆ°åˆ—åï¼š{strain_col}ï¼Œè¯·ç¡®è®¤å­˜å‚¨GCA/GCFæ ‡è¯†çš„åˆ—å")
    
    # 5. æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´—Strain_IDåˆ—ï¼Œé¿å…å‰ç¼€è¯†åˆ«å¤±è´¥ï¼‰
    df[strain_col] = df[strain_col].astype(str).str.strip()  # è½¬ä¸ºå­—ç¬¦ä¸²+å»å‰åç©ºæ ¼
    print(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ï¼š{input_file}")
    print(f"ğŸ“Š åŸå§‹æ€»è¡Œæ•°ï¼š{len(df)}")
    
    # 6. ç­›é€‰ï¼šä¿ç•™GCF_å‰ç¼€è¡Œï¼Œåˆ é™¤GCA_å‰ç¼€è¡Œ
    # ç»Ÿè®¡å„å‰ç¼€è¡Œæ•°
    gcf_count = df[df[strain_col].str.startswith("GCF_", na=False)].shape[0]
    gca_count = df[df[strain_col].str.startswith("GCA_", na=False)].shape[0]
    other_count = len(df) - gcf_count - gca_count  # æ—¢ä¸æ˜¯GCFä¹Ÿä¸æ˜¯GCAçš„è¡Œ
    
    print(f"\nğŸ“‹ å‰ç¼€åˆ†å¸ƒç»Ÿè®¡ï¼š")
    print(f"   GCF_å‰ç¼€è¡Œæ•°ï¼š{gcf_count}ï¼ˆå°†ä¿ç•™ï¼‰")
    print(f"   GCA_å‰ç¼€è¡Œæ•°ï¼š{gca_count}ï¼ˆå°†åˆ é™¤ï¼‰")
    print(f"   å…¶ä»–å‰ç¼€è¡Œæ•°ï¼š{other_count}ï¼ˆå°†ä¿ç•™ï¼‰")
    
    # æ‰§è¡Œç­›é€‰
    df_filtered = df[
        (df[strain_col].str.startswith("GCF_", na=False)) |  # ä¿ç•™GCF_
        (~df[strain_col].str.startswith(("GCA_", "GCF_"), na=False))  # ä¿ç•™å…¶ä»–å‰ç¼€
    ].copy()
    
    print(f"\nğŸ“Š ç­›é€‰åæ€»è¡Œæ•°ï¼š{len(df_filtered)}")
    print(f"ğŸ—‘ï¸  å·²åˆ é™¤GCA_å‰ç¼€è¡Œæ•°ï¼š{gca_count}")
    
    # 7. å¯é€‰ï¼šç­›é€‰åè¿›è¡Œé¢å¤–å»é‡ï¼ˆå¦‚éœ€å»é‡åˆ™æ‰§è¡Œï¼‰
    if subset is not None:
        # æ•°æ®æ¸…æ´—ï¼ˆè§£å†³å»é‡ä¸ç”Ÿæ•ˆé—®é¢˜ï¼‰
        for col in df_filtered.columns:
            if df_filtered[col].dtype == "object":
                df_filtered[col] = df_filtered[col].astype(str).str.strip()
        if ignore_null:
            df_filtered = df_filtered.replace(["nan", ""], None)
        else:
            df_filtered = df_filtered.replace("nan", None)
        
        # æ‰§è¡Œå»é‡
        original_filtered_rows = len(df_filtered)
        df_filtered = df_filtered.drop_duplicates(
            subset=subset,
            keep=keep,
            ignore_index=True
        )
        deduplicated_rows = len(df_filtered)
        removed_dup_rows = original_filtered_rows - deduplicated_rows
        
        print(f"\nğŸ” é¢å¤–å»é‡ï¼ˆåŸºäºåˆ—ï¼š{subset}ï¼‰ï¼š")
        print(f"   å»é‡å‰è¡Œæ•°ï¼š{original_filtered_rows}")
        print(f"   å»é‡åè¡Œæ•°ï¼š{deduplicated_rows}")
        print(f"   ç§»é™¤é‡å¤è¡Œæ•°ï¼š{removed_dup_rows}")
    
    # 8. è¦†ç›–æºæ–‡ä»¶
    try:
        df_filtered.to_excel(input_file, index=False, engine="openpyxl")
        print(f"\nâœ… å·²ç›´æ¥è¦†ç›–æºæ–‡ä»¶ï¼š{input_file}")
    except Exception as e:
        # è¦†ç›–å¤±è´¥æ—¶æ¢å¤å¤‡ä»½
        shutil.copy2(backup_file, input_file)
        raise RuntimeError(f"è¦†ç›–æºæ–‡ä»¶å¤±è´¥ï¼å·²è‡ªåŠ¨æ¢å¤åŸæ–‡ä»¶ï¼š{str(e)}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Excelç­›é€‰å·¥å…·ï¼šä¿ç•™GCF_å‰ç¼€ï¼Œåˆ é™¤GCA_å‰ç¼€ï¼ˆç›´æ¥è¦†ç›–æºæ–‡ä»¶ï¼‰")
    parser.add_argument("-i", "--input", required=True, help="è¾“å…¥Excelæ–‡ä»¶è·¯å¾„ï¼ˆ.xlsx/.xlsï¼‰")
    parser.add_argument("-c", "--strain-col", default="Strain_ID", help="å­˜å‚¨GCA/GCFæ ‡è¯†çš„åˆ—åï¼ˆé»˜è®¤ï¼šStrain_IDï¼‰")
    parser.add_argument("-s", "--subset", nargs="+", help="ç­›é€‰åé¢å¤–å»é‡çš„åŸºå‡†åˆ—ï¼ˆå¦‚ï¼š_serotype serotyponï¼Œé»˜è®¤ï¼šä¸å»é‡ï¼‰")
    parser.add_argument("-k", "--keep", choices=["first", "last", "False"], default="first", 
                        help="é‡å¤è¡Œä¿ç•™ç­–ç•¥ï¼ˆfirst=ä¿ç•™é¦–æ¬¡ï¼Œlast=ä¿ç•™æœ€åï¼ŒFalse=åˆ é™¤æ‰€æœ‰ï¼Œé»˜è®¤ï¼šfirstï¼‰")
    parser.add_argument("-n", "--no-ignore-null", action="store_true", help="ä¸å¿½ç•¥ç©ºå€¼å·®å¼‚ï¼ˆé»˜è®¤ï¼šå¿½ç•¥ï¼‰")
    
    args = parser.parse_args()
    
    # å¤„ç†keepå‚æ•°
    keep_param = args.keep if args.keep != "False" else False
    
    # æ‰§è¡Œç­›é€‰
    try:
        excel_filter_gcf_override(
            input_file=args.input,
            strain_col=args.strain_col,
            subset=args.subset,
            keep=keep_param,
            ignore_null=not args.no_ignore_null
        )
        print("\nğŸ‰ å¤„ç†å®Œæˆï¼å·²ä¿ç•™GCF_å‰ç¼€è¡Œï¼Œåˆ é™¤GCA_å‰ç¼€è¡Œï¼ˆæºæ–‡ä»¶å·²æ›´æ–°ï¼‰")
    except Exception as e:
        print(f"\nâŒ å‡ºé”™ï¼š{str(e)}")
